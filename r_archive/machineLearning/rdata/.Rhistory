group <- c("A","A","A","A","B","B","B","B","B")
maanwhitney <- cbind(score,group)
maanwhitney
order <- rank(score)
order
score
maanwhitney <- cbind(maanwhitney, order)
maanwhitney
tapply(order, group, sum)
n1 <- 20
n2 <- 20
N <- n1 * n2
Utable <- matrix(c(1:N), ncol <- n1 , byrow = TRUE)
Utable
?matrix
Utable <- matrix(c(1:N), ncol <- n1)
Utable
Utable <- matrix(c(1:N), ncol <- n1, byrow = TRUE)
for (m in 1:20)
{}
for (m in 1:20)
{
for (n in 1:20)
{
Utable[m,n] <- qwilcox(.05,m,n)
}
}
m
n
Utable
?qwilcox
wilcox.test(order ~ group)
wilcox.test(score ~ group)
load("C:/Users/vdl/Documents/R/Beginning R Data/mwsmall.rda")
mwsmall
load("C:/Users/vdl/Documents/R/Beginning R Data/mwlarge.rda")
mwlarge
maanwhitney
mannwhitney
mannwhitneylarge
head(mannwhitneylarge)
attach(mannwhitneylarge)
rr <- rank(Leaders)
mannwhitneylarge <- cbind(mannwhitneylarge, rr)
mannwhitneylarge
tapply(Leaders,Control,var)
tapply(rr, Control, sum)
wilcox.test(Leader ~ Control)
wilcox.test(Leaders ~ Control)
2 * (1- pnorm(2.2238))
signedRanks
attach(signedRanks)
wilcox.test(treatment, contro, paried = TRUE)
wilcox.test(treatment, control, paried = TRUE)
treatment
control
wilcox.test(treatment, control)
wilcox.test(treatment, control, paried = TRUE)
x = c(11.2, 11.0, 12.0, 13.0, 12.5, 10.5, 5.8, 6.2, 14.0, 12.2)
sign.test <- function(median, y){
z = sort(y)
n = length(z)
b = sum(z > median)
pbinom(b-1, n, 0.5, lower.tail=FALSE)
}
sign.test(10,x)
A지역 <- c(158, 105, 72, 125, 56, 129, 63, 161, 190, 114, 43, 27)
B지역 <- c(124, 169, 76, 24, 62, 95, 142, 79, 112, 64, 61, 106, 126, 162,
83, 91, 153, 148, 21, 107, 167,65, 109, 42)
wilcox.test(A지역, B지역, alternative= "g", exact = TRUE)
A <- c(3, 5, 10, 14, 30)
B <- c(6, 8, 12, 13, 20)
C <- c(2, 4,  9, 16, 27, 28)
list(A,B,C)
A
kruskal.test(list(A,B,C))
var(A)
var(B)
var(C)
x <- c(95, 70, 60, 73, 62, 71, 75)
y <- c(88, 65, 63, 78, 70, 76, 73)
cor.test(x,y, method = "spearm")
x
rank(x)
x <- 1
y <- 2
a = c(1,2,3)
a
b = 1:10
b
a = matrix(1:12, ncol=3)
a
t.test(a)
t.test(b)
accdata
bingedata
head(bingedata)
head(hours)
head(dataset)
t.test(Quiz1 ~ Sex)
attach(dataset)
t.test(Quiz1 ~ Sex)
summary(Quiz1)
summary(Quiz1 ~ Sex)
x <- c(1,20,0.1)
y <- sin(x)
plot(x,y)
plot(y,x)
x
x <- seq(1,20,0.1)
y <- sin(x)
plot(x,y)
plot(x,y,type = "l")
plank <- 1:8
plank
dim(plank) <- c(2,4)
plank
dim(plank) <- c(2,3)
dim(plank) <- c(4,2
)
plank
persp(plank)
persp(plank,expand=0.2)
contour(plank)
image(plank)
micromid
micrototal
std <- sd(micrototal)
std
summary(micrototal)
plot(micrototal )
barplot(micrototal)
setwd("C:/Users/vdl/git/lockdpwn/r_archive/machineLearning/rdata")
academy <- read.csv("academy.csv", stringsAsFactors = F, header = T)
academy
head(academy)
dist_academy <- dist(academy, method="euclidean")
head(dist_academy)
dist_academy
food <- read.csv("food.csv", stringsAsFactors = F, header=T)
food <- food[-1]
academy <- academy[-1]
dist_academy <- dist(academy, method="euclidean")
dist_academy
food.mult <- t(as.matrix(food)) %*% as.matrix(food)
skin <- read.csv("read.csv", header= T)
skin <- read.csv("skin.csv", header= T)
skin <- skin[-1]
str(skin)
mat_academy <- as.matrix(dist_academy)
temp_mat <- mat_academy[1:5, 1:5]
rownames(temp_mat) <- LETTERS[1:5]
temp_mat
colnames(temp_mat) <- LETTERS[1:5]
diag(temp_mat) <- rep(9999,5)
temp_mat
pos <- which(temp_mat == min(temp_mat))[1]
pos
rown <- pos %/% 5 + 1
rown
coln <- pos %% 5 ; if (coln == 0) rown = rown - 1 ; coln = 5
coln
temp_mat2 <- temp_mat[c(-2,-4) , c(-2,-4)]
temp_mat2 <- rbind(temp_mat2, BD = rep(0,3))
temp_mat2
temp_mat2 <- cbind(temp_mat2, BD = rep(0,3))
temp_mat2
c(-2,-5)
new_distance <- c()
new_distance
for (i in setdiff(c(1:5), c(2,4))) { #1,3,5}
new_distance <- c(new_distance, min(temp_mat[i,2] , temp_mat[i,4])) }
for (i in setdiff(c(1:5), c(2,4))) { #1,3,5
new_distance <- c(new_distance, min(temp_mat[i,2] , temp_mat[i,4])) }
new_distance
new_distance <- c(new_distance,9999)
new_distance
temp_mat2[dim(temp_mat2)[1],] <- new_distance
temp_mat2
temp_mat2[,dim(temp_mat2)[1]] <- new_distance
new_distance <- new_distance[-4]
new_distance
new_distance <- new_distance[-4]
new_distance
new_distance <- new_distance[-1]
new_distance
new_distance <- new_distance[-1]
new_distance <- new_distance[-1]
new_distance <- new_distance[-1]
new_distance
new_distance <- new_distance[-1]
for (i in setdiff(c(1:5), c(2,4))) { #1,3,5
new_distance <- c(new_distance, min(temp_mat[i,2] , temp_mat[i,4])) }
new_distance <- c(new_distance,9999)
new_distance
temp_mat2[,dim(temp_mat2)[1]] <- new_distance
temp_mat2[dim(temp_mat2)[1],] <- new_distance
temp_mat2
pos <- which(temp_mat2 == min(temp_mat2))[1]
rown <- pos %/% 4 + 1
coln <- pos %% 4 ; if (coln == 0) rown = rown -1 ; coln=4
coln
rown
temp_mat3 <- temp_mat2[c(-3,-4) , c(-3,-4)]
temp_mat3 <- rbind(temp_mat3, BD = rep(0,3))
temp_mat3 <- cbind(temp_mat3, BED = rep(0,3))
temp_mat3 <- rbind(temp_mat3, BED = rep(0,3))
temp_mat3
dis <- function(x,y) {}
dis <- function(x,y){
return ((x[1] - x[2])^2 + (y[1] - y[2])^2)
}
x <- c(rnom(20,3,1), rnorm(20,7,1))
x <- c(rnorm(20,3,1), rnorm(20,7,1))
x
help(rnorm)
rnorm(5,3,1)
y <- c(rnorm(20,4,1), rnorm(20,8,1))
plot(x,y, cex=.5, xlim=c(0,10), ylim=c(0,10))
setwd("C:/Users/vdl/git/lockdpwn/r_archive/machineLearning/rcode")
c <- locator(2) ; print(c)
points(c$x , c$y , pch=20 , col="red")
c <- locator(2) ; print(c)
points(c$x , c$y , pch=20 , col="red")
plot(x,y, cex=.5, xlim=c(0,10), ylim=c(0,10))
help(locator)
help(points)
help(locator)
c <- locator(2) ; print(c)
points(c$x , c$y , pch=20 , col="red")
distance1 <- c()
for (i in 1:length(x)){
lines(c(x[i], c$x[i]), c(y[i], c$y[1]), lty=2))
lines(c(x[i], c$x[i]), c(y[i], c$y[1]), lty=2)
for (i in 1:length(x)){
lines(c(x[i], c$x[i]), c(y[i], c$y[1]), lty=2)
distance1 <- c(distance1, dis
a
for (i in 1:length(x)){
lines(c(x[i], c$x[1]), c(y[i], c$y[1]), lty=2)
distance1 <- c(distance1, dis(c(x[i], c$x[1]), c(y[i], c$y[1])))
}
distance1
x
plot(x,y , cex = 5, xlim = c(0,10), ylim=c(0,10))
points(c$x, c$y, pch=20, col="red")
distance2 <- c()
for (i in 1:length(x)){
lines(c(x[i], c$x[2]), c(y[i], c$y[2]), lty=2)
distance2 <- c(distance2, dis(c(x[i], c$x[2]), c(y[i], c$y[2])))
}
plot(x,y , cex = .5, xlim = c(0,10), ylim=c(0,10))
for (i in 1:length(x)){
+ lines(c(x[i], c$x[2]), c(y[i], c$y[2]), lty=2)
+ distance2 <- c(distance2, dis(c(x[i], c$x[2]), c(y[i], c$y[2])))
+ }
for (i in 1:length(x)){
lines(c(x[i], c$x[2]), c(y[i], c$y[2]), lty=2)
distance2 <- c(distance2, dis(c(x[i], c$x[2]), c(y[i], c$y[2]))) }
points(c$x, c$y, pch=20, col="red")
clusters <- c()
f <- factor(distance1 > distance2)
f
levels(f) <- c("1", "2")
f
x1_var <- mean(x[f == "1"])
x1_var
x2_var <- mean(x[f == "2"])
y1_var <- mean(y[f == "1"])
y2_var <- mean(y[f == "2"])
x1_var;x2_var;y1_var;y2_var
f
x
y
length(x)
length(f)
distance1
clear(f)
cls(f)
rm(f)
f
f <- factor(distance1 > distance2)
f
distance1
distance2
type(distance2)
distance2 <- distance2[1:(length(distance2)-40)]
distance2
rm(f)
f <- factor(distance1 > distance2)
f
levels(x = f) <- c("1","2")
f
x1_var <- mean(x[f == "1"])
x2_var <- mean(x[f == "2"])
y1_var <- mean(y[f == "1"])
y2_var <- mean(y[f == "2"])
x1_var
x1_var,x2_var,y1_var,y2_var
x1_var;x2_var;y1_var;y2_var
c$x - c(x1_var, x2_var)
c$y - c(y1_var, y2_var)
help("cancor")
library(cluster)
hcl <- hclust(dist(academy)^2 , method="single")
hcl
plot(hcl, hang=-1 , xlam = "strudent", ylab = "distance")
plot(hcl, hang=-1 , xlam = "student", ylab = "distance")
academy
setwd("C:/Users/vdl/git/lockdpwn/r_archive/machineLearning/rdata")
head(academy)
library(graphics)
kms <- kmeans(academy, 5); kms
plot(academy, col = kms$cluster)
wss <- 0
for(i in 1:10) wss[i] <- sum(kmeans(academy, centers = i)$withinss)
wss
plot(1:10, wss ,type="b", xlab = "number of clusters", ylab = "within group sum of squares")
like <- read.csv("like.csv", stringsAsFactors = F, header = T)
colnames(like) <- c("talk", "book", "travel", "school", "tall", "skin", "muscle","label")
like
test <- data.frame(talk = 70, book= 50, travel= 30, school =70 , tall =70, skin = 40, muscle=50)
test
library(class)
train <- like[,-8]
train
group <- like[,8]
group
knnpred1 <- knn(train, test, group, k=3, prob = TRUE)
knnpred
knnpred1
knnpred2 <- knn(train, test, group, k=4, prob = TRUE)
knnpred2
buy <- read.csv("buy.csv", stringsAsFactors = F, header = T)
buy$age <- scale(buy$나이)
buy$pay <- scale(buy$월수입)
buy
test <- data.frame((age =44, pay=400))
test <- data.frame(age =44, pay=400)
test
train <- buy[,c(4,5)]
train
label <- buy[,3]
label
test$age <- (test$age - mean(buy$나이)) / sd(buy$나이)
test$pay <- (test$pay - mean(buy$월수입)) / sd(buy$월수입)
knnpred1 <- knn(train, test, labels, k=5, prob=TRUE)
knnpred1 <- knn(train, test, label, k=5, prob=TRUE)
knnpred2 <- knn(train, test, label, k=6, prob=TRUE)
knnpred1
knnpred2
movie <- read.csv("movie.csv", header =T)
head(movie)
Sys.getlocale()
Sys.getlocale()
movie
head(movie)
library(e1071)
nm <- naiveBayes(movie[1:5], movie$장르, laplacce = 0)
nm <- naiveBayes(movie[1:5], movie$장르, laplace = 0)
nm
result <- predict(nm, movie[1:5])
result
summary(nm)
mail <- read.csv("spam.csv", header = T)
head(mail)
mail[is.na[mail]] <- 0
mail[is.na(mail)] <- 0
head(mail)
nm2 <- naiveBayes(mail[2:13], mail$메일종류, laplace=0)
nm2
results <- predic
results <- predict(nm2, mail[2:13])
result2 <- predict(nm2, mail[2:13])
result2
nm2
result2
mail
nm
help("naiveBayes")
install.packages("KoLNP")
install.packages("KoNLP")
library(KoNLP)
txt <- readLines('spam.txt')
txt <- readLines('spam.txt')
usesejong
nm2
building <- read.csv("building.csv", header =T)
head(building)
building[is.na(building)] <- 0
head(building)
building <- building[-1]
head(building)
build <- building
rm(building)
build
library(arules)
install.packages(arules)
install.packages("arules")
library(arules)
trans <- as.matrix(build, "Transaction")
trans
help("as.matrix")
trans <- as.matrix(build, "Transaction")
build
trans
str(trans)
str(build)
rules1 <- apriori(trans, parameter = list(supp=0.2, conf=0.6, target="rules"))
rules1``
rules1
sort(rules1)
inspect(sort(rules1))
rules2 <- subset(rules1, subset= lhs %pin% '보습학원' & confidence > 0.7)
inspect(sort(rules2))
rules3 <- subset(rules1, subset= rhs %pin% '편의점' & confidence > 0.7)
inspect(sort(rules3))
rules4 <- subset(rules1 , subset = lhs %pin% '당구장' & confid)
rules4 <- subset(rules1 , subset = lhs %pin% '당구장' & confidence > 0.7)
rules4
inspect(sort(rules4))
b2
b2 <- t(as.matrix(build)) %*% as.matrix(build)
library(sna)
install.packages("sna")
library(sna)
library(rgl)
install.packages("rgl")
library(rgl)
b2
diag(b2)
diag(diag(b2))
help(diag)
b2.w <- b2 - diag(diag(b2))
b2.w
#rownames(b2.w)
#colnames
#colnames(b2.w)
gplot(b2.w, displaylabels = T, vertex.cex =sqrt(daig(b2)), vertex.col = "green", edge.col = "blue", boxed.labels =F, arrowhead.cex = .3 , label.pos = 3, edge.lwd =b2.w * 2)
gplot(b2.w, displaylabels = T, vertex.cex =sqrt(diag(b2)), vertex.col = "green", edge.col = "blue", boxed.labels =F, arrowhead.cex = .3 , label.pos = 3, edge.lwd =b2.w * 2)
gplot(b2.w, displaylabels = T, vertex.cex =sqrt(diag(b2)), vertex.col = "green", edge.col = "blue", boxed.labels =T, arrowhead.cex = .3 , label.pos = 3, edge.lwd =b2.w * 2)
gplot(b2.w, displaylabels = T, vertex.cex =sqrt(diag(b2)), vertex.col = "green", edge.col = "blue", boxed.labels =F, arrowhead.cex = .3 , label.pos = 3, edge.lwd =b2.w * 2)
gplot(b2.w, displaylabels = T, vertex.cex =sqrt(diag(b2)), vertex.col = "green", edge.col = "blue", boxed.labels =F, arrowhead.cex = .3 , label.pos = 3, edge.lwd =b2.w * 2)
gplot(b2.w, displaylabels = T, vertex.cex =sqrt(diag(b2)), vertex.col = "green", edge.col = "blue", boxed.labels =F, arrowhead.cex = .3 , label.pos = 3, edge.lwd =b2.w * 2)
gplot(b2.w, displaylabels = T, vertex.cex =sqrt(diag(b2)), vertex.col = "green", edge.col = "blue", boxed.labels =F, arrowhead.cex = .3 , label.pos = 3, edge.lwd =b2.w)
gplot(b2.w, displaylabels = T, vertex.cex =sqrt(diag(b2)), vertex.col = "green", edge.col = "blue", boxed.labels =F, arrowhead.cex = .3 , label.pos = 3, edge.lwd =b2.w)
gplot(b2.w, displaylabels = T, vertex.cex =sqrt(diag(b2)), vertex.col = "green", edge.col = "blue", boxed.labels =F, arrowhead.cex = .3 , label.pos = 3, edge.lwd =b2.w)
gplot(b2.w, displaylabels = T, vertex.cex =sqrt(diag(b2)), vertex.col = "green", edge.col = "blue", boxed.labels =F, arrowhead.cex = .3 , label.pos = 3, edge.lwd =b2.w * 2)
gplot(b2.w, displaylabels = T, vertex.cex =sqrt(diag(b2)), vertex.col = "green", edge.col = "blue", boxed.labels =F, arrowhead.cex = .3 , label.pos = 3, edge.lwd =b2.w * 2)
gplot(b2.w, displaylabels = T, vertex.cex =sqrt(diag(b2)), vertex.col = "green", edge.col = "blue", boxed.labels =F, arrowhead.cex = .3 , label.pos = 3, edge.lwd =b2.w * 2)
gplot(b2.w, displaylabels = T, vertex.cex =sqrt(diag(b2)), vertex.col = "red", edge.col = "blue", boxed.labels =F, arrowhead.cex = .3 , label.pos = 3, edge.lwd =b2.w * 2)
gplot(b2.w, displaylabels = T, vertex.cex =sqrt(diag(b2)), vertex.col = "red", edge.col = "blue", boxed.labels =F, arrowhead.cex = .3 , label.pos = 3, edge.lwd =b2.w * 2)
gplot(b2.w, displaylabels = T, vertex.cex =sqrt(diag(b2)), vertex.col = "green", edge.col = "red", boxed.labels =F, arrowhead.cex = .3 , label.pos = 3, edge.lwd =b2.w * 2)
gplot(b2.w, displaylabels = T, vertex.cex =sqrt(diag(b2)), vertex.col = "green", edge.col = "cyan", boxed.labels =F, arrowhead.cex = .3 , label.pos = 3, edge.lwd =b2.w * 2)
gplot(b2.w, displaylabels = T, vertex.cex =sqrt(diag(b2)), vertex.col = "green", edge.col = "cyan", boxed.labels =F, arrowhead.cex = .3 , label.pos = 3, edge.lwd =b2.w * 2)
gplot(b2.w, displaylabels = T, vertex.cex =sqrt(diag(b2)), vertex.col = "green", edge.col = "cyan", boxed.labels =F, arrowhead.cex = .3 , label.pos = 3, edge.lwd =b2.w * 2)
clear
clear()
cls
cls()
cls()
library(KoNLP)
usesej
library(tm)
install.packages(tm)
install.packages("tm")
install.packages()
install.packages("KoNLP")
libra\
library(KoNLP)
help(as)
library(KoNLP)
useSejongDic()
library()
library(tm)
docs <- read.csv("sms_spam.csv")
docs <- read.csv("sms_spam.csv", header =T, stringsAsFactors = F)
head(docks)
head(docs0
head(docs0
head(docs)
docs
corpus <- Corpus(DataframeSource(docs[,1:2]))
head(corpus)
inspect(corpus[1:3])
courpus
corpus
inspect(corpus)
inspect(corpus[1:3])
corpus_clean <- tm_map(corpus, tolower)
corpus_clean
corpus_clean <- tm_map(corpus_clean, removeNumbers)
docs
corpus <- Corpus(DataframeSource(docs[,1:2]))
inspect(corpus[1:3])
corpus_clean <- tm_map(corpus_clean, removeWords, stopwords())
corpus_clean <- tm_map(corpus_clean, removePunctuation)
lapply(corpus, as.character)
corpus_clean
inspect(corpus_clean
)
inspect(corpus_clean)
help(lappy)
help(lapply)
lapply(corpus_clean, as.character)
lapply(corpus, as.character)
sms_dtm <- TermDocumentMatrix(corpus, control = list(weighting = weightTfIdf))
inspect(sms_dtm)
sms_dtm3 <- TermDocumentMatrix(corpus)
inspect(sms_dmt3)
inspect(sms_dtm3)
findFreqTerms(TermDocumentMatrix(corpus), lowfreq =2)
