help("cancor")
library(cluster)
hcl <- hclust(dist(academy)^2 , method="single")
hcl
plot(hcl, hang=-1 , xlam = "strudent", ylab = "distance")
plot(hcl, hang=-1 , xlam = "student", ylab = "distance")
academy
setwd("C:/Users/vdl/git/lockdpwn/r_archive/machineLearning/rdata")
head(academy)
library(graphics)
kms <- kmeans(academy, 5); kms
plot(academy, col = kms$cluster)
wss <- 0
for(i in 1:10) wss[i] <- sum(kmeans(academy, centers = i)$withinss)
wss
plot(1:10, wss ,type="b", xlab = "number of clusters", ylab = "within group sum of squares")
like <- read.csv("like.csv", stringsAsFactors = F, header = T)
colnames(like) <- c("talk", "book", "travel", "school", "tall", "skin", "muscle","label")
like
test <- data.frame(talk = 70, book= 50, travel= 30, school =70 , tall =70, skin = 40, muscle=50)
test
library(class)
train <- like[,-8]
train
group <- like[,8]
group
knnpred1 <- knn(train, test, group, k=3, prob = TRUE)
knnpred
knnpred1
knnpred2 <- knn(train, test, group, k=4, prob = TRUE)
knnpred2
buy <- read.csv("buy.csv", stringsAsFactors = F, header = T)
buy$age <- scale(buy$나이)
buy$pay <- scale(buy$월수입)
buy
test <- data.frame((age =44, pay=400))
test <- data.frame(age =44, pay=400)
test
train <- buy[,c(4,5)]
train
label <- buy[,3]
label
test$age <- (test$age - mean(buy$나이)) / sd(buy$나이)
test$pay <- (test$pay - mean(buy$월수입)) / sd(buy$월수입)
knnpred1 <- knn(train, test, labels, k=5, prob=TRUE)
knnpred1 <- knn(train, test, label, k=5, prob=TRUE)
knnpred2 <- knn(train, test, label, k=6, prob=TRUE)
knnpred1
knnpred2
movie <- read.csv("movie.csv", header =T)
head(movie)
Sys.getlocale()
Sys.getlocale()
movie
head(movie)
library(e1071)
nm <- naiveBayes(movie[1:5], movie$장르, laplacce = 0)
nm <- naiveBayes(movie[1:5], movie$장르, laplace = 0)
nm
result <- predict(nm, movie[1:5])
result
summary(nm)
mail <- read.csv("spam.csv", header = T)
head(mail)
mail[is.na[mail]] <- 0
mail[is.na(mail)] <- 0
head(mail)
nm2 <- naiveBayes(mail[2:13], mail$메일종류, laplace=0)
nm2
results <- predic
results <- predict(nm2, mail[2:13])
result2 <- predict(nm2, mail[2:13])
result2
nm2
result2
mail
nm
help("naiveBayes")
install.packages("KoLNP")
install.packages("KoNLP")
library(KoNLP)
txt <- readLines('spam.txt')
txt <- readLines('spam.txt')
usesejong
nm2
building <- read.csv("building.csv", header =T)
head(building)
building[is.na(building)] <- 0
head(building)
building <- building[-1]
head(building)
build <- building
rm(building)
build
library(arules)
install.packages(arules)
install.packages("arules")
library(arules)
trans <- as.matrix(build, "Transaction")
trans
help("as.matrix")
trans <- as.matrix(build, "Transaction")
build
trans
str(trans)
str(build)
rules1 <- apriori(trans, parameter = list(supp=0.2, conf=0.6, target="rules"))
rules1``
rules1
sort(rules1)
inspect(sort(rules1))
rules2 <- subset(rules1, subset= lhs %pin% '보습학원' & confidence > 0.7)
inspect(sort(rules2))
rules3 <- subset(rules1, subset= rhs %pin% '편의점' & confidence > 0.7)
inspect(sort(rules3))
rules4 <- subset(rules1 , subset = lhs %pin% '당구장' & confid)
rules4 <- subset(rules1 , subset = lhs %pin% '당구장' & confidence > 0.7)
rules4
inspect(sort(rules4))
b2
b2 <- t(as.matrix(build)) %*% as.matrix(build)
library(sna)
install.packages("sna")
library(sna)
library(rgl)
install.packages("rgl")
library(rgl)
b2
diag(b2)
diag(diag(b2))
help(diag)
b2.w <- b2 - diag(diag(b2))
b2.w
#rownames(b2.w)
#colnames
#colnames(b2.w)
gplot(b2.w, displaylabels = T, vertex.cex =sqrt(daig(b2)), vertex.col = "green", edge.col = "blue", boxed.labels =F, arrowhead.cex = .3 , label.pos = 3, edge.lwd =b2.w * 2)
gplot(b2.w, displaylabels = T, vertex.cex =sqrt(diag(b2)), vertex.col = "green", edge.col = "blue", boxed.labels =F, arrowhead.cex = .3 , label.pos = 3, edge.lwd =b2.w * 2)
gplot(b2.w, displaylabels = T, vertex.cex =sqrt(diag(b2)), vertex.col = "green", edge.col = "blue", boxed.labels =T, arrowhead.cex = .3 , label.pos = 3, edge.lwd =b2.w * 2)
gplot(b2.w, displaylabels = T, vertex.cex =sqrt(diag(b2)), vertex.col = "green", edge.col = "blue", boxed.labels =F, arrowhead.cex = .3 , label.pos = 3, edge.lwd =b2.w * 2)
gplot(b2.w, displaylabels = T, vertex.cex =sqrt(diag(b2)), vertex.col = "green", edge.col = "blue", boxed.labels =F, arrowhead.cex = .3 , label.pos = 3, edge.lwd =b2.w * 2)
gplot(b2.w, displaylabels = T, vertex.cex =sqrt(diag(b2)), vertex.col = "green", edge.col = "blue", boxed.labels =F, arrowhead.cex = .3 , label.pos = 3, edge.lwd =b2.w * 2)
gplot(b2.w, displaylabels = T, vertex.cex =sqrt(diag(b2)), vertex.col = "green", edge.col = "blue", boxed.labels =F, arrowhead.cex = .3 , label.pos = 3, edge.lwd =b2.w)
gplot(b2.w, displaylabels = T, vertex.cex =sqrt(diag(b2)), vertex.col = "green", edge.col = "blue", boxed.labels =F, arrowhead.cex = .3 , label.pos = 3, edge.lwd =b2.w)
gplot(b2.w, displaylabels = T, vertex.cex =sqrt(diag(b2)), vertex.col = "green", edge.col = "blue", boxed.labels =F, arrowhead.cex = .3 , label.pos = 3, edge.lwd =b2.w)
gplot(b2.w, displaylabels = T, vertex.cex =sqrt(diag(b2)), vertex.col = "green", edge.col = "blue", boxed.labels =F, arrowhead.cex = .3 , label.pos = 3, edge.lwd =b2.w * 2)
gplot(b2.w, displaylabels = T, vertex.cex =sqrt(diag(b2)), vertex.col = "green", edge.col = "blue", boxed.labels =F, arrowhead.cex = .3 , label.pos = 3, edge.lwd =b2.w * 2)
gplot(b2.w, displaylabels = T, vertex.cex =sqrt(diag(b2)), vertex.col = "green", edge.col = "blue", boxed.labels =F, arrowhead.cex = .3 , label.pos = 3, edge.lwd =b2.w * 2)
gplot(b2.w, displaylabels = T, vertex.cex =sqrt(diag(b2)), vertex.col = "red", edge.col = "blue", boxed.labels =F, arrowhead.cex = .3 , label.pos = 3, edge.lwd =b2.w * 2)
gplot(b2.w, displaylabels = T, vertex.cex =sqrt(diag(b2)), vertex.col = "red", edge.col = "blue", boxed.labels =F, arrowhead.cex = .3 , label.pos = 3, edge.lwd =b2.w * 2)
gplot(b2.w, displaylabels = T, vertex.cex =sqrt(diag(b2)), vertex.col = "green", edge.col = "red", boxed.labels =F, arrowhead.cex = .3 , label.pos = 3, edge.lwd =b2.w * 2)
gplot(b2.w, displaylabels = T, vertex.cex =sqrt(diag(b2)), vertex.col = "green", edge.col = "cyan", boxed.labels =F, arrowhead.cex = .3 , label.pos = 3, edge.lwd =b2.w * 2)
gplot(b2.w, displaylabels = T, vertex.cex =sqrt(diag(b2)), vertex.col = "green", edge.col = "cyan", boxed.labels =F, arrowhead.cex = .3 , label.pos = 3, edge.lwd =b2.w * 2)
gplot(b2.w, displaylabels = T, vertex.cex =sqrt(diag(b2)), vertex.col = "green", edge.col = "cyan", boxed.labels =F, arrowhead.cex = .3 , label.pos = 3, edge.lwd =b2.w * 2)
clear
clear()
cls
cls()
cls()
library(KoNLP)
usesej
library(tm)
install.packages(tm)
install.packages("tm")
install.packages()
install.packages("KoNLP")
libra\
library(KoNLP)
help(as)
library(KoNLP)
useSejongDic()
library()
library(tm)
docs <- read.csv("sms_spam.csv")
docs <- read.csv("sms_spam.csv", header =T, stringsAsFactors = F)
head(docks)
head(docs0
head(docs0
head(docs)
docs
corpus <- Corpus(DataframeSource(docs[,1:2]))
head(corpus)
inspect(corpus[1:3])
courpus
corpus
inspect(corpus)
inspect(corpus[1:3])
corpus_clean <- tm_map(corpus, tolower)
corpus_clean
corpus_clean <- tm_map(corpus_clean, removeNumbers)
docs
corpus <- Corpus(DataframeSource(docs[,1:2]))
inspect(corpus[1:3])
corpus_clean <- tm_map(corpus_clean, removeWords, stopwords())
corpus_clean <- tm_map(corpus_clean, removePunctuation)
lapply(corpus, as.character)
corpus_clean
inspect(corpus_clean
)
inspect(corpus_clean)
help(lappy)
help(lapply)
lapply(corpus_clean, as.character)
lapply(corpus, as.character)
sms_dtm <- TermDocumentMatrix(corpus, control = list(weighting = weightTfIdf))
inspect(sms_dtm)
sms_dtm3 <- TermDocumentMatrix(corpus)
inspect(sms_dmt3)
inspect(sms_dtm3)
findFreqTerms(TermDocumentMatrix(corpus), lowfreq =2)
library(KoNLP)
useSejongDic()
library(tm)
docs <- read.csv("sms_spam.csv", header = T, stringsAsFactors = F)
docs
corpus <- Corpus(DataframeSource(docs[,1:2]))
corpus
inspect(corpus([1:3]))
inspect(corpus[1:3])
corpus_clean <- tm_map(corpus, tolower)
corpus_clean <- tm_map(corpus_clean, removeNumbers)
corpus_clean <- tm_map(corpus_clean, removeWords, stopwords())
corpus_clean <- tm_map(corpus_clean, removePunctuation)
lapply(corpus, as.character)
lapply(corpus_clean, as.character)
sms_dtm <- TermDocumentMatrix(corpus, control= list(weighting=weightTfIdf))
inspect(sms_dtm)
sms_dtm3 <- TermDocumentMatrix(corpus)
sms_dtm3
inspect(sms_dtm3)
findFreqTerms(TermDocumentMatrix(corpus), lowfreq=2)
findAssocs(TermDocumentMatrix(corpus),"user", 0.5)
sms_dtm2 <- DocumentTermMatrix(corpus, control = list(weighting = weightTfIdf))
inspect(sms_dtm2)
library(caret)
install.packages("caret")
install.packages("rpart")
library(caret)
library(rpart)
library(nnet)
sms_dtm2_df <- cbind(as.data.frame(as.matrix(sms_dmt2)), LABEL = docs$type )
sms_dtm2_df <- cbind(as.data.frame(as.matrix(sms_dtm2)), LABEL = docs$type )
sms_dtm2_df
m <- nnet(LABEL ~. , data = sms_dtm2_df, size=3)
predict(m, newdata = sms_dtm2_df)
predict(m, newdata = sms_dtm2_df)
m <- nnet(LABEL ~. , data = sms_dtm2_df, size=3)
predict(m, newdata = sms_dtm2_df)
advice <- read.csv("advice.csv", header=T, stringsAsFactors = F)
advice
open(advice)
open("advice.csv"
)
place <- sapply(advice[,2], extractNoum, USE.NAMES = F)
place <- sapply(advice[,2], extractNoun, USE.NAMES = F)
place
c <- unlist(place)
c
place2 <- Filter(function(x), {nchar(x) >= 2 & nchar(x) <= 5)}, c)
place2 <- Filter(function(x) {nchar(x) >= 2 & nchar(x) <= 5)}, c)
place2 <- Filter(function(x) {nchar(x) >= 2 & nchar(x) <= 5},c)
place2
res <- str_replace_all(place2, "[^[:alpha:]]" , "")
library("stringr")
res <- str_replace_all(place2, "[^[:alpha:]]" , "")
res
res <- res[res != ""]
res
wordcount <- table(res)
wordcount
wordcount2 <- sort(table(res), decreasing = T)
wordcount2
library(wordcloud)
install.packages("wordcloud")
install.packages("RColorBrewer")
palete <- brewer.pal(8, "Set2")
library(wordcloud)
library(RColorBrewer)
palete <- brewer.pal(8, "Set2")
palete
wordcloud(names(wordcount), freq = wordcount , scale=c(3,1), rot.per = 0.25, min.freq = 1, random.order = F, random.color = T, colors = palete)
c(3,1)
keyword <- dimnames(wordcount2[1:10])$res
keyword
keyword <- dimnames(wordcount2[1:10])
keyword
keyword <- dimnames(wordcount2[1:10])$res
keyword
contents <- c()
contents
for (i in 1:6){
inter <- intersect(place[[i]], keyword)
contents <- rbind(contents, table(inter)[keyword])
}
contents
inter
rownames(contents) <- advice$DATE
colname(contents) <- keyword
colnames(contents) <- keyword
contents
contents[which(is.na(contents))] <- 0
contents
advice2 <- read.csv("advice2.csv", header =T ,stringsAsFactors = F)
rownames(advice2) <- advice2[,1]
advice2
advice2 <- advice2[-1]
head(advice2)
advice3 <- ifelse(advice2 > mean(apply(advice2, 2, mean)), 1 ,0)
head(advice3)
library(arules)
trans <- as.matrix(advice3, "Transaction")
trans
head(trans)
rules1 <- apriori(trans, parameter = list(supp=0.3, conf=0.7, target="rules"))
rules1
inspect(sort(rules1))
inspect(sort(rules1))
inspect(rules1)
help(inspect)
arules::inspect(sort(rules1))
rules2 <- subset(rules1, subset = lhs %pin% '초밥' & confidence > 0.7)
rules2
arules::inspect(sort(rules2))
rules2 <- subset(rules1, subset = lhs %pin% '초밥')
arules::inspect(sort(rules2))
image(trans)
library(arulesViz)
install.packages("arulesViz")
library(arulesViz)
plot(rules1)
plot(rules1, method="grouped")
plot(rules1)
plot(rules1, method="grouped")
plot(rules1, method="graph")
plot(rules1, method="graph", control = list(type="items"))
plot(rules1, method="paracoord", control = list(reorder = TRUE)
)
cor(advice2)
library(corrgram)
install.packages("corrgram")
library(corrgram)
corrgram(cor(advice2))
library(corrplot)
install.packages("corrplot")
library(corrplot)
corrplot(cor(advice2))
libcurlVersion(sna)
library(sna)
library(rgl)
advice_square <- t(as.matrix(advice2)) %*% as.matrix(advice2)
advice_square
gplot(sqrt(sqrt(advice_square)), displaylabel = T, vertex.cex = sqrt(diag(advice_square)) * 0.01, label = rownames(advice_square), edge.col = "blue", boxed.labels = F, arrowhead.cex = 0.01, edge.lwd = 0.01, vertex.alpha = 0.01)
gplot(sqrt(sqrt(advice_square)), displaylabel = T, vertex.cex = sqrt(diag(advice_square)) * 0.01, label = rownames(advice_square), edge.col = "blue", vertex.col = "green", boxed.labels = F, arrowhead.cex = 0.01, edge.lwd = 0.01, vertex.alpha = 0.01)
gplot(sqrt(sqrt(advice_square)), displaylabel = T, vertex.cex = sqrt(diag(advice_square)) * 0.01, label = rownames(advice_square), edge.col = "orange", vertex.col = "green", boxed.labels = F, arrowhead.cex = 0.01, edge.lwd = 0.01, vertex.alpha = 0.01)
gplot(sqrt(sqrt(advice_square)), displaylabel = T, vertex.cex = sqrt(diag(advice_square)) * 0.01, label = rownames(advice_square), edge.col = "orange", vertex.col = "green", boxed.labels = F, arrowhead.cex = 0.01, edge.lwd = 0.01)
help(gplot)
library(zoo)
dates <- as.Date(rownames(advice2), format="%Y-%m-%d")
dates
time_keywords <- zoo(advice2, dates)
time_keywords
plot(time_keywords)
help(zoo)
ccf(advice2$고등어, advice2$연어, main = "고등어 vs 연어")
help(ccf)
drink <- read.csv("drink.csv", header = T)
drink
str(drink)
attach(drink)
library(class)
m <-glm(지각여부 ~ 나이 + 결혼여부 + 자녀여부 + 체력 + 주량 + 직급 + 성별, family = binomial(link=logit), data = drink)
m
predict(m, drink, tpye="response")
predict(m, drink, type="response")
predict(m, drink, type="response") >= 0.5)
predict(m, drink, type="response") >= 0.5
table(drink$지각여부, predict(m, drink, type="response") > 0.5)
drink$지각여부
ball <- read.csv("ball.csv", header = T)
ball
str(ball)
library(nnet)
m2 <- multinom(선물 ~ . , data = ball)
m2
cbind(fitted(m2) , levels(ball$선물)[ball$선물])
predicted <- levels(ball$선물)[apply(fitted(m2), 1, which.max)]
predicted
sum(predicted != ball$선물)
xtabs(~ predicted + ball$선물)
test <- read.csv("rule.csv", header = T)
test
P--[[;///]]
r1 <- NROW(subset(test, 효과 == "YES")) / NROW(test)
r1
r2 <- NROW(subset(test, 효과 == "NO")) / NROW(test)
r2
cond1 <- subset(test, 과목 == "수학" & 수업일 == "주말")
cond1
f1 <- NROW(subset(cond1, 효과 == "YES"))
f2 <- NROW(subset(cond1, 효과 == "NO"))
e1 <- NROW(cond1) * r1
f1
f2
e1
r1
r2
e2 <- NROW(cond1) * r2
e2
like11 <- 2 * (f1 * log(f1/e1) + f2 * log(f2/e2))
like1 <- 2 * (f1 * log(f1/e1) + f2 * log(f2/e2))
like1
cove <- NROW(cond1) / NROW(test)
test <- read.csv("rule.csv", header = T)
r1 <- NROW(subset(test, 효과 == "YES")) / NROW(test)
r2 <- NROW(subset(test, 효과 == "NO")) / NROW(test)
like_cov_acc <- function(cond, res)
{
f1 <- NROW(subset(cond1, 효과 == "YES"))
f2 <- NROW(subset(cond1, 효과 == "NO"))
e1 <- NROW(cond1) * r1
e2 <- NROW(cond1) * r2
like <- 2 * (f1 * log(f1/e1) + f2 * log(f2/e2))
# 적용도 coverage와 정확도 accuracy
cove <- NROW(cond1) / NROW(test)
acc <- NROW(subset(cond1, 효과 == "NO")) / NROW(cond1)
cat("적용도는", cove, "입니다\n")
cat("정확도는", acc, "입니다\n")
cat("기능도비율은", like, "입니다\n")
}
# RULE 1
cond1 <- subset(test, 과목 == "수학" & 수업일 == "주말")
res1 = "NO"
like_cov_acc(cond1, res1)
# RULE 2
cond2 <- subset(test, 과목 == "과학")
res2 <- "NO"
like_cov_acc(cond2, res2)
# RULE 3
cond3 <- subset(test, (과목 == "과학" | 과목 == "수학") & 수업시간대 == "저녁" & (class == "A" | classs == "B"))
res3 <- "NO"
like_cov_acc(cond3, res3)
# RULE 4
cond4 <- subset(test, (과목 == "국어" | 과목 == "영어") & (class == "A" | classs == "B"))
res4 <- "NO"
like_cov_acc(cond4, res4)
test <- read.csv("rule.csv", header = T)
r1 <- NROW(subset(test, 효과 == "YES")) / NROW(test)
r2 <- NROW(subset(test, 효과 == "NO")) / NROW(test)
like_cov_acc <- function(cond, res)
{
f1 <- NROW(subset(cond, 효과 == "YES"))
f2 <- NROW(subset(cond, 효과 == "NO"))
e1 <- NROW(cond) * r1
e2 <- NROW(cond) * r2
like <- 2 * (f1 * log(f1/e1) + f2 * log(f2/e2))
# 적용도 coverage와 정확도 accuracy
cove <- NROW(cond) / NROW(test)
acc <- NROW(subset(cond, 효과 == res)) / NROW(cond)
cat("적용도는", cove, "입니다\n")
cat("정확도는", acc, "입니다\n")
cat("기능도비율은", like, "입니다\n")
}
# RULE 1
cond1 <- subset(test, 과목 == "수학" & 수업일 == "주말")
res1 = "NO"
like_cov_acc(cond1, res1)
# RULE 2
cond2 <- subset(test, 과목 == "과학")
res2 <- "NO"
like_cov_acc(cond2, res2)
# RULE 3
cond3 <- subset(test, (과목 == "과학" | 과목 == "수학") & 수업시간대 == "저녁" & (class == "A" | classs == "B"))
res3 <- "NO"
like_cov_acc(cond3, res3)
# RULE 4
cond4 <- subset(test, (과목 == "국어" | 과목 == "영어") & (class == "A" | classs == "B"))
res4 <- "NO"
like_cov_acc(cond4, res4)
cond3 <- subset(test, (과목 == "과학" | 과목 == "수학") & 수업시간대 == "저녁" & (class == "A" | classs == "B"))
test <- read.csv("rule.csv", header = T)
r1 <- NROW(subset(test, 효과 == "YES")) / NROW(test)
r2 <- NROW(subset(test, 효과 == "NO")) / NROW(test)
like_cov_acc <- function(cond, res)
{
f1 <- NROW(subset(cond, 효과 == "YES"))
f2 <- NROW(subset(cond, 효과 == "NO"))
e1 <- NROW(cond) * r1
e2 <- NROW(cond) * r2
like <- 2 * (f1 * log(f1/e1) + f2 * log(f2/e2))
# 적용도 coverage와 정확도 accuracy
cove <- NROW(cond) / NROW(test)
acc <- NROW(subset(cond, 효과 == res)) / NROW(cond)
cat("적용도는", cove, "입니다\n")
cat("정확도는", acc, "입니다\n")
cat("기능도비율은", like, "입니다\n")
}
# RULE 1
cond1 <- subset(test, 과목 == "수학" & 수업일 == "주말")
res1 = "NO"
like_cov_acc(cond1, res1)
# RULE 2
cond2 <- subset(test, 과목 == "과학")
res2 <- "NO"
like_cov_acc(cond2, res2)
# RULE 3
cond3 <- subset(test, (과목 == "과학" | 과목 == "수학") & 수업시간대 == "저녁" & (class == "A" | class == "B"))
res3 <- "NO"
like_cov_acc(cond3, res3)
# RULE 4
cond4 <- subset(test, (과목 == "국어" | 과목 == "영어") & (class == "A" | class == "B"))
res4 <- "NO"
like_cov_acc(cond4, res4)
