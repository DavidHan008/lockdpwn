a
View(b2)
b
b2
str(b2)
str(b)
str(a)
cardh
card_history <- read.csv('card_history2.csv', header =T ,stringsAsFactors = F)
card_history
library(reshape2)
card_history <- card_history
card_history <- card_history[-1]
card_history
card2 <- melt(id = 1, card_history, na.rm = TRUE)
card2
card2 <- melt(id = 0, card_history, na.rm = TRUE)
card2
card2 <- melt(id = 1, card_history, na.rm = TRUE)
card2 <- subset(card2, value != 'N')
head(card2)
card2
library(class)
card2$WEEK <- as.interger(card2$WEEK)
card2$WEEK <- as.integer(card2$WEEK)
card2$WEEK
colnames(card2)[2:3] <- c("WEEK", "FOOD")
card2[card2$FOOD == 'Y', "FOOD"] <- "N"
card2
card2[card2$FOOD == 'F', "FOOD"] <- "Y"
card2
card2$WEEK <- as.integer(card2$WEEK)
card2
card2$월 <- as.integer(as.factor(card2$월))
knnpred <- knn(card2[1:2], card2[1:2], card2$FOOD, k = 2, prob=TRUE)
knnpred
help(knn)
table(knnpred, card2$FOOD)
test <- data.frame(TIME=c(15,16,17), WEEK = c(4,4,4))
test
knnpred <- knn(card2[1:2], test, card2$FOOD, k = 5, prob=TRUE)
knnpred
attributes(knnpred)$prob > 0.65
attributes(knnpred)$prob
corrplot(cor(prob))
library(corrplot)
corrplot(cor(prob))
prob <- read.csv('prob3.csv', header=T, stringsAsFactors = F)
prob
prob <- prob[-1]
cor(prob)
corrplot(cor(prob))
prob$total_score <- prob$만족도 + prob$우울증
prob$total_score
plot(density(prob$total_score) , main = "TOTAL SCORE")
prob[abs(mean(prob$total_score) - prob$total_score) > sd(prob$total_score)]
plot[abs(mean(prob$total_score) - prob$total_score) > sd(prob$total_score)]
prob[abs(mean(prob$total_score) - prob$total_score) > sd(prob$total_score),]
family1=rep(c("G8"),50)
family2=rep(c("V4"),30)
x1=runif(50, min=-2.7, max=3.0)
x2=runif(50, min=-2.7, max=3.0)
x3=runif(50, min=-2.7, max=3.0)
x4=runif(50, min=-2.7, max=3.0)
x5=runif(50, min=-2.7, max=3.0)
x6=runif(50, min=-2.7, max=3.0)
x7=runif(50, min=-2.7, max=3.0)
x8=runif(50, min=-2.7, max=3.0)
x9=runif(50, min=-2.7, max=3.0)
x10=runif(50, min=-2.7, max=3.0)
x11=runif(50, min=-2.7, max=3.0)
x12=runif(50, min=-2.7, max=3.0)
G8<-cbind(family1, x1, x2, x3, x4, x5, x6, x7, x8, x9, x10, x11, x12)
G8_Final<-as.data.frame(G8)
y1=runif(30, min=-2.7, max=3.0)
y2=runif(30, min=-2.7, max=3.0)
y3=runif(30, min=-2.7, max=3.0)
y4=runif(30, min=-2.7, max=3.0)
y5=runif(30, min=-2.7, max=3.0)
y6=runif(30, min=-2.7, max=3.0)
y7=runif(30, min=-2.7, max=3.0)
y8=runif(30, min=-2.7, max=3.0)
y9=runif(30, min=-2.7, max=3.0)
y10=runif(30, min=-2.7, max=3.0)
y11=runif(30, min=-2.7, max=3.0)
y12=runif(30, min=-2.7, max=3.0)
V4<-cbind(family2, y1, y2, y3, y4, y5, y6, y7, y8, y9, y10, y11, y12)
V4_Final<-as.data.frame(V4)
N <- 1000
V <- matrix(c(1,.8,.8,1),2)
d <- mvrnorm(N, mu=c(0,0), Sigma=V)
par(mar=c(2,2,4,2))
windows(height=7, width=10)
plot(d, d1,
xlim=c(-2,2), ylim=c(-2,2),
axes = FALSE,
xlab="", ylab="",
main="Contour plot of the Mahalanobis distance to the origin",
col="red",
pch=19)
box()
abline(h=0, v=0, lty=3)
x <- seq(min(d[,1]), max(d[,1]), length=100)
y <- seq(min(d[,2]), max(d[,2]), length=100)
z <- outer(x, y, function (x, y) {
sqrt(apply(rbind(x,y) * solve(V, rbind(x,y)), 2, sum))
} )
contour(x, y, z,
add = TRUE,
col = "blue", lwd = 3)
library(MASS)
#Produce a Gaussian correlation structure for Gaussian distributions
#N number of samples required
#mu= a vector giving the means of the variables
#Sigma=a positive definite symmetric matrix specifiying the covariance matrix of the variables
##G8 (dataframe with 12 columns - independent variables - and 50 rows)
##### Covariance matrix and mean vector
N <-50
V <-cov(plot_G8)
mu<-colMeans(V)
d <- mvrnorm(N, mu, Sigma=V)
head(d)
tail(d)
##V4 (dataframe with 12 columns - independent variables - and 30 rows)
##### Covariance matrix and mean vector
N1 <-30
V1 <-cov(plot_V4)
mu1<-colMeans(V1)
d1 <- mvrnorm(N1, mu1, Sigma=V1)
head(d1)
tail(d1)
####Plot the contour plot for G8 (d)
windows(height=7, width=10)
par(mar=c(2,2,4,2))
plot.new()
plot(d,
xlim=c(-3,3), ylim=c(-3,3),
axes = TRUE,
xlab="", ylab="",
main="Contour plot of the Mahalanobis distance to the origin",
col="orangered1",
pch=19)
box()
abline(h=0, v=0, lty=3, col="blue")
#Sequence along the minimum and maximum value for x and y in d
x <- seq(min(d[,1]), max(d[,1]), length=50)
y <- seq(min(d[,2]), max(d[,2]), length=50)
Construct a matrix of values for the dependent variable
for the outer product of the two vectors x and y
to evaluate all combinations of each vectors values
#solve() function solves equation a %*% x=b for x
#where b is a vector or matrix
#a=V=rbind(x,y)
z <- outer(x, y, function (x, y){
sqrt(apply(rbind(x,y) * solve(V, rbind(x,y)), 50, sum))
})
#Error message
Error in solve.default(V, rbind(x, y)) :
'b' (2 x 2500) must be compatible with 'a' (50 x 50)
contour(x, y, z, add = TRUE, col = "blue", lwd = 3, levels=10)
#####Plot the contour plot for V4 (d1)
par(mar=c(2,2,4,2))
windows(height=7, width=10)
plot.new()
plot(d1, xlim=c(-2,2), ylim=c(-2,2),
axes = FALSE,
xlab="", ylab="",
main="Contour plot of the Mahalanobis distance to the origin",
col="mediumseagreen",
pch=19)
#Error message
Error in solve.default(V, rbind(x, y)) :
'b' (2 x 2500) must be compatible with 'a' (50 x 50)
box()
abline(h=0, v=0, lty=3, col="blue")
x <- seq(min(d[,1]), max(d[,1]), length=30)
y <- seq(min(d[,2]), max(d[,2]), length=30)
z <- outer(x, y, function (x, y) {
sqrt(apply(rbind(x,y) * solve(V, rbind(x,y)), 30, sum))
} )
contour(x, y, z, add = TRUE, col = "blue", lwd = 3)
library(StatMatch)
#Code to produce the dummy data can be found at the bottom of this page
data(G8_Final)
data(v4_Final)
##Calculate the Mahalanobis distance for G8
distance.scores1<-mahalanobis.dist(G8_Final, data.y=NULL, vc=NULL)
plot_G8<-as.data.frame(distance.scores1)
##Calculate the Mahalanobis distance for V4
distance.scores2<-mahalanobis.dist(V4_Final, data.y=NULL, vc=NULL)
plot_V4<-as.data.frame(distance.scores2)
install.packages("StatMatch")
install.packages("MASS")
install.packages("MASS")
library(StatMatch)
#Code to produce the dummy data can be found at the bottom of this page
data(G8_Final)
data(v4_Final)
##Calculate the Mahalanobis distance for G8
distance.scores1<-mahalanobis.dist(G8_Final, data.y=NULL, vc=NULL)
plot_G8<-as.data.frame(distance.scores1)
##Calculate the Mahalanobis distance for V4
distance.scores2<-mahalanobis.dist(V4_Final, data.y=NULL, vc=NULL)
plot_V4<-as.data.frame(distance.scores2)
Error in solve.default(V, rbind(x, y)) :
'b' (2 x 2500) must be compatible with 'a' (50 x 50)
family1=rep(c("G8"),50)
family2=rep(c("V4"),30)
x1=runif(50, min=-2.7, max=3.0)
x2=runif(50, min=-2.7, max=3.0)
x3=runif(50, min=-2.7, max=3.0)
x4=runif(50, min=-2.7, max=3.0)
x5=runif(50, min=-2.7, max=3.0)
x6=runif(50, min=-2.7, max=3.0)
x7=runif(50, min=-2.7, max=3.0)
x8=runif(50, min=-2.7, max=3.0)
x9=runif(50, min=-2.7, max=3.0)
x10=runif(50, min=-2.7, max=3.0)
x11=runif(50, min=-2.7, max=3.0)
x12=runif(50, min=-2.7, max=3.0)
G8<-cbind(family1, x1, x2, x3, x4, x5, x6, x7, x8, x9, x10, x11, x12)
G8_Final<-as.data.frame(G8)
y1=runif(30, min=-2.7, max=3.0)
y2=runif(30, min=-2.7, max=3.0)
y3=runif(30, min=-2.7, max=3.0)
y4=runif(30, min=-2.7, max=3.0)
y5=runif(30, min=-2.7, max=3.0)
y6=runif(30, min=-2.7, max=3.0)
y7=runif(30, min=-2.7, max=3.0)
y8=runif(30, min=-2.7, max=3.0)
y9=runif(30, min=-2.7, max=3.0)
y10=runif(30, min=-2.7, max=3.0)
y11=runif(30, min=-2.7, max=3.0)
y12=runif(30, min=-2.7, max=3.0)
V4<-cbind(family2, y1, y2, y3, y4, y5, y6, y7, y8, y9, y10, y11, y12)
V4_Final<-as.data.frame(V4)
library(StatMatch)
#Code to produce the dummy data can be found at the bottom of this page
data(G8_Final)
data(v4_Final)
##Calculate the Mahalanobis distance for G8
distance.scores1<-mahalanobis.dist(G8_Final, data.y=NULL, vc=NULL)
plot_G8<-as.data.frame(distance.scores1)
##Calculate the Mahalanobis distance for V4
distance.scores2<-mahalanobis.dist(V4_Final, data.y=NULL, vc=NULL)
plot_V4<-as.data.frame(distance.scores2)
library(MASS)
#Produce a Gaussian correlation structure for Gaussian distributions
#N number of samples required
#mu= a vector giving the means of the variables
#Sigma=a positive definite symmetric matrix specifiying the covariance matrix of the variables
##G8 (dataframe with 12 columns - independent variables - and 50 rows)
##### Covariance matrix and mean vector
N <-50
V <-cov(plot_G8)
mu<-colMeans(V)
d <- mvrnorm(N, mu, Sigma=V)
head(d)
tail(d)
##V4 (dataframe with 12 columns - independent variables - and 30 rows)
##### Covariance matrix and mean vector
N1 <-30
V1 <-cov(plot_V4)
mu1<-colMeans(V1)
d1 <- mvrnorm(N1, mu1, Sigma=V1)
head(d1)
tail(d1)
####Plot the contour plot for G8 (d)
windows(height=7, width=10)
par(mar=c(2,2,4,2))
plot.new()
plot(d,
xlim=c(-3,3), ylim=c(-3,3),
axes = TRUE,
xlab="", ylab="",
main="Contour plot of the Mahalanobis distance to the origin",
col="orangered1",
pch=19)
box()
abline(h=0, v=0, lty=3, col="blue")
#Sequence along the minimum and maximum value for x and y in d
x <- seq(min(d[,1]), max(d[,1]), length=50)
y <- seq(min(d[,2]), max(d[,2]), length=50)
Construct a matrix of values for the dependent variable
for the outer product of the two vectors x and y
to evaluate all combinations of each vectors values
#solve() function solves equation a %*% x=b for x
#where b is a vector or matrix
#a=V=rbind(x,y)
z <- outer(x, y, function (x, y){
sqrt(apply(rbind(x,y) * solve(V, rbind(x,y)), 50, sum))
})
#Error message
Error in solve.default(V, rbind(x, y)) :
'b' (2 x 2500) must be compatible with 'a' (50 x 50)
contour(x, y, z, add = TRUE, col = "blue", lwd = 3, levels=10)
#####Plot the contour plot for V4 (d1)
par(mar=c(2,2,4,2))
windows(height=7, width=10)
plot.new()
plot(d1, xlim=c(-2,2), ylim=c(-2,2),
axes = FALSE,
xlab="", ylab="",
main="Contour plot of the Mahalanobis distance to the origin",
col="mediumseagreen",
pch=19)
#Error message
Error in solve.default(V, rbind(x, y)) :
'b' (2 x 2500) must be compatible with 'a' (50 x 50)
box()
abline(h=0, v=0, lty=3, col="blue")
x <- seq(min(d[,1]), max(d[,1]), length=30)
y <- seq(min(d[,2]), max(d[,2]), length=30)
z <- outer(x, y, function (x, y) {
sqrt(apply(rbind(x,y) * solve(V, rbind(x,y)), 30, sum))
} )
contour(x, y, z, add = TRUE, col = "blue", lwd = 3)
windows(height=7, width=10)
plot(d, d1,
xlim=c(-3,3), ylim=c(-3,3),
axes = TRUE,
xlab="", ylab="",
main="Contour plot of the Mahalanobis distance to the origin",
col=c("orangered1", "mediumseagreen" ),
pch=c(17:19))
#Error message
Error during wrapup: 'x' and 'y' lengths differ
N <- 1000
V <- matrix(c(1,.8,.8,1),2)
d <- mvrnorm(N, mu=c(0,0), Sigma=V)
par(mar=c(2,2,4,2))
windows(height=7, width=10)
plot(d, d1,
xlim=c(-2,2), ylim=c(-2,2),
axes = FALSE,
xlab="", ylab="",
main="Contour plot of the Mahalanobis distance to the origin",
col="red",
pch=19)
box()
abline(h=0, v=0, lty=3)
x <- seq(min(d[,1]), max(d[,1]), length=100)
y <- seq(min(d[,2]), max(d[,2]), length=100)
z <- outer(x, y, function (x, y) {
sqrt(apply(rbind(x,y) * solve(V, rbind(x,y)), 2, sum))
} )
contour(x, y, z,
add = TRUE,
col = "blue", lwd = 3)
require(graphics)
ma <- cbind(1:6, 1:3)
(S <-  var(ma))
mahalanobis(c(0, 0), 1:2, S)
x <- matrix(rnorm(100*3), ncol = 3)
stopifnot(mahalanobis(x, 0, diag(ncol(x))) == rowSums(x*x))
##- Here, D^2 = usual squared Euclidean distances
Sx <- cov(x)
D2 <- mahalanobis(x, colMeans(x), Sx)
plot(density(D2, bw = 0.5),
main="Squared Mahalanobis distances, n=100, p=3") ; rug(D2)
qqplot(qchisq(ppoints(100), df = 3), D2,
main = expression("Q-Q plot of Mahalanobis" * ~D^2 *
" vs. quantiles of" * ~ chi[3]^2))
abline(0, 1, col = 'gray')
#WORKING EXAMPLE
#MAHALANOBIS DIST OF TWO MATRICES
#define matrix
mat1<-matrix(data=c(2,2,6,7,4,6,5,4,2,1,2,5,5,3,7,4,3,6,5,3),nrow=10)
mat2<-matrix(data=c(6,7,8,5,5,5,4,7,6,4),nrow=5)
#center data
mat1.1<-scale(mat1,center=T,scale=F)
mat2.1<-scale(mat2,center=T,scale=F)
#cov matrix
mat1.2<-cov(mat1.1,method="pearson")
mat2.2<-cov(mat2.1,method="pearson")
n1<-nrow(mat1)
n2<-nrow(mat2)
n3<-n1+n2
#pooled matrix
mat3<-((n1/n3)*mat1.2) + ((n2/n3)*mat2.2)
#inverse pooled matrix
mat4<-solve(mat3)
#mean diff
mat5<-as.matrix((colMeans(mat1)-colMeans(mat2)))
#multiply
mat6<-t(mat5) %*% mat4
#multiply
sqrt(mat6 %*% mat5)
mahalanobis(x, center, cov, inverted = FALSE, ...)
N <- 1000
d <- matrix(rnorm(2*N), nc=2)
par(mar=c(2,2,4,2))
plot(d, xlim=c(-2,2), ylim=c(-2,2),
axes = FALSE,
xlab="", ylab="",
main="Contour plot of the Euclidian distance to the origin")
box()
abline(h=0, v=0, lty=3)
x <- seq(min(d[,1]), max(d[,1]), length=100)
y <- seq(min(d[,2]), max(d[,2]), length=100)
z <- outer(x, y, function (x,y) sqrt(x^2 + y^2))
contour(x, y, z,
add = TRUE,
col = "blue", lwd = 3)
x
y
z
d
head(d[,1])
N <- 5000
library(MASS)
d <- mvrnorm(N, mu=c(0,0), Sigma=matrix(c(1,.8,.8,1),2))
par(mar=c(2,2,4,2))
plot(d, xlim=c(-2,2), ylim=c(-2,2),
axes = FALSE,
xlab="", ylab="",
main="Contour plot of the Euclidian distance to the origin")
box()
abline(h=0, v=0, lty=3)
x <- seq(min(d[,1]), max(d[,1]), length=100)
y <- seq(min(d[,2]), max(d[,2]), length=100)
z <- outer(x, y, function (x,y) sqrt(x^2 + y^2))
contour(x, y, z,
add = TRUE,
col = "blue", lwd = 1)
points(sqrt(2)*c(1,-1), sqrt(2)*c(1,1),
lwd = 10, cex = 5, pch = 4, col = "blue")
text(sqrt(2)*c(1,-1), sqrt(2)*c(1,1) + .1,
c("2", "1"),
pos = 3, adj = .5,
font = 2, cex = 3, col = "blue")
train_datase
test_dataset = read.csv('../../../python_archive/machineLearning/Iris_test.dat')
test_dataset
test_dataset = read.csv('../../../python_archive/machineLearning/Iris_test.dat',header =T)
test_dataset
test_dataset = read.csv('../../../python_archive/machineLearning/Iris_test.dat',header =T, stringsAsFactors = F)
test_dataset
test_dataset[1]
test_dataset[,1]
test_dataset = read.csv('../../../python_archive/machineLearning/Iris_test.dat',header =F)
test_dataset[,1]
test_dataset
train_dataset = read.csv('../../../python_archive/machineLearning/Iris_train.dat',header =F)
head(train_dataset)
test_dataset
test_dataset[-1]
test_dataset[-3]
test_dataset[-3,-4]
test_dataset[-3:-4]
testData = test_dataset[-3:-4]
test_dataset[5]
testClass = test_dataset[5]
testData = test_dataset[-3:-5]
testData
length(testData)
length(test_dataset)
help(length)
str(testData)
trainClass = train_dataset[5]
trainClass
c1x = train_dataset[1:2]
c1x
c1x = train_dataset[1:2][0:40]
c1x = train_dataset[1:2,40]
c1x
c1x = train_dataset[1:2,:40]
str(c1x)
str(train_dataset)
c1x = subset(train_dataset, select = c(V1,V2), subset = (0:40))
c1x = train_dataset[1:2,0:40]
c1x = train_dataset[1:2,1:40]
c1x = train_dataset[1:2,c(1:40)]
train_dataset[1:2,1:40]
train_dataset[1:2]
train_dataset[1:40,1:2]
c1x = train_dataset[1:40,1:2]
c1x
c1 = train_dataset[1:40,1]
c1x = train_dataset[1:40,1]
c1y = train_dataset[1:40,2]
c1
c2
c1x
c1 = train_dataset[1:40,1:2]
c1
c2
c1x
c1y
c1 = train_dataset[41:80,1:2]
c1 = train_dataset[1:40,1:2]
c2 = train_dataset[41:80,1:2]
c2
str(c2)
c2x = train_dataset[41:80,1]
c2y = train_dataset[41:80,2]
c3 = train_dataset[81:120,1:2]
c3x = train_dataset[81:120,1]
c3y = train_dataset[81:120,2]
c3
c2
c1
c1.mean()
mena(c1)
mean(c1)
mean(c1)
mean(c1x)
mean(c1y)
std(c1x)
var(c1x)
std
sd(c1x)
