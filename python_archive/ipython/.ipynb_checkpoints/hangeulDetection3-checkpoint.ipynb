{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import scipy.misc\n",
    "import scipy.io\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------------------------------------\n",
    "# train\n",
    "train_images = []\n",
    "tlabels = []\n",
    "\n",
    "# train Image 데이터 700장을 불러온다\n",
    "# train Label 데이터를 불러온다\n",
    "with h5py.File('C:/Users/edward/GoogleDrive/private2/machineLearningData/visualComputing_hangeul/kalph_train.hf', 'r') as hf:\n",
    "    train_images = np.array(hf['images'])\n",
    "    tlabels = np.array(hf['labels'])\n",
    "\n",
    "\n",
    "# Image 데이터와 Label 데이터를 numpy 데이터로 수정한다\n",
    "train_images = train_images.reshape(19600, 2704, )\n",
    "\n",
    "\n",
    "# train Label 데이터를 [1 x 100] 의 행렬로 표현한다\n",
    "#           예를 들어 3이면 [0,0,1,0,.....,0] 과 같이 설정한다\n",
    "train_labels  = np.array(np.zeros(254800).reshape(19600,13))\n",
    "for num in range(0,19600):\n",
    "    train_labels[num][int(tlabels[num]) - 1] = 1\n",
    "\n",
    "\n",
    "\n",
    "#-----------------------------------------------------------------\n",
    "# test\n",
    "test_images = []\n",
    "testlabels = []\n",
    "\n",
    "\n",
    "# train Image 데이터 700장을 불러온다\n",
    "# train Label 데이터를 불러온다\n",
    "with h5py.File('C:/Users/edward/GoogleDrive/private2/machineLearningData/visualComputing_hangeul/kalph_test.hf', 'r') as hf:\n",
    "    test_images = np.array(hf['images'])\n",
    "    testlabels = np.array(hf['labels'])\n",
    "\n",
    "\n",
    "\n",
    "# Image 데이터와 Label 데이터를 numpy 데이터로 수정한다\n",
    "test_images = test_images.reshape(3920, 2704, )\n",
    "\n",
    "# train Label 데이터를 [1 x 100] 의 행렬로 표현한다\n",
    "#           예를 들어 3이면 [0,0,1,0,.....,0] 과 같이 설정한다\n",
    "test_labels  = np.array(np.zeros(50960).reshape(3920,13))\n",
    "for num in range(0,3920):\n",
    "    test_labels[num][int(testlabels[num]) - 1] = 1\n",
    "\n",
    "\n",
    "# 중요! Image 데이터들은 0~255 사이의 값이므로 255로 나눠주면서 정규화를 한다. 학습이 매우 잘된다\n",
    "train_images = train_images / 255.\n",
    "test_images =  test_images / 255.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------------------------------------\n",
    "\n",
    "_num_examples, bins = train_images.shape\n",
    "# _num_examples : 데이터 갯수\n",
    "\n",
    "_index_in_epoch = 0   # epoch\n",
    "_images = train_images  # Image 변수 \n",
    "_labels = train_labels  # Label 변수\n",
    "_epochs_completed = 0   \n",
    "\n",
    "# batch 연산을 수행하는 함수\n",
    "# 호출될 때마다 랜덤으로 batch_size의 (Image, Label) 데이터를 반환한다\n",
    "def next_batch(batch_size):\n",
    "    \"\"\"Return the next `batch_size` examples from this data set.\"\"\"\n",
    "    global _index_in_epoch\n",
    "    global _images\n",
    "    global _labels\n",
    "    global _epochs_completed\n",
    "\n",
    "    start = _index_in_epoch\n",
    "    _index_in_epoch += batch_size\n",
    "\n",
    "    if _index_in_epoch > _num_examples:\n",
    "      # Finished epoch\n",
    "      _epochs_completed += 1\n",
    "\n",
    "      # Shuffle the data\n",
    "      perm = np.arange(_num_examples)\n",
    "      np.random.shuffle(perm)\n",
    "      _images = _images[perm]\n",
    "      _labels = _labels[perm]\n",
    "\n",
    "      # Start next epoch\n",
    "      start = 0\n",
    "      _index_in_epoch = batch_size\n",
    "      assert batch_size <= _num_examples\n",
    "\n",
    "    end = _index_in_epoch\n",
    "    return _images[start:end], _labels[start:end]\n",
    "\n",
    "\n",
    "# 가중치를 초기화하는 함수 (정규분포 stddev=0.1로 초기화한다)\n",
    "def weight_variable(shape):\n",
    "\tinitial = tf.truncated_normal(shape, stddev=0.1)\n",
    "\treturn tf.Variable(initial)\n",
    "\n",
    "\n",
    "# 바이어스를 초기화하는 함수 (0.1로 초기화한다)\n",
    "def bias_variable(shape):\n",
    "\tinitial = tf.constant(0.1, shape=shape)\n",
    "\treturn tf.Variable(initial)\n",
    "\n",
    "\n",
    "# 컨벌루션을 실행하는 함수\n",
    "# padding = 'SAME' 입력과 출력의 이미지 크기가 같도록 해준다\n",
    "# (28,28) --> (28,28)\n",
    "# padding = 'VALID' 필터의 크기만큼 이미지 크기가 감소한다\n",
    "def conv2d_valid(x, W):\n",
    "\treturn tf.nn.conv2d(x, W, strides=[1,1,1,1], padding='VALID')\n",
    "\n",
    "\n",
    "def conv2d_same(x, W):\n",
    "\treturn tf.nn.conv2d(x, W, strides=[1,1,1,1], padding='SAME')\n",
    "\n",
    "\n",
    "# max pooling을 실행하는 함수\n",
    "def max_pool_2x2(x):\n",
    "\treturn tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#-----------------------------------------------------------------\n",
    "# Tensorflow 코드\n",
    "#-----------------------------------------------------------------\n",
    "\n",
    "x = tf.placeholder(\"float32\", [None, 2704]) # mnist data image of shape 52 * 52 = 2704\n",
    "y = tf.placeholder(\"float32\", [None, 13]) \n",
    "\n",
    "W = tf.Variable(tf.zeros([2704,13]))\n",
    "b = tf.Variable(tf.zeros([13]))\n",
    "\n",
    "\n",
    "# 1st conv layer ----------------------\n",
    "W_conv1 = weight_variable([5,5,1,32])\n",
    "b_conv1 = bias_variable([32])\n",
    "\n",
    "# -1 : 아직 디멘젼이 결정되지 않았다\n",
    "# 1 : 흑백이므로 1을 삽입한다. 칼라이면 3을 삽입한다\n",
    "# x은 2200x1인데 55x40x1로 행렬을 다시 만들어준다\n",
    "x_image = tf.reshape(x, [-1, 52, 52, 1])\n",
    "\n",
    "# y = x*w + b에 ReLU를 적용한다\n",
    "h_conv1 = tf.nn.relu(conv2d_same(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)  # (52,52) ==> (26,26)\n",
    "\n",
    "\n",
    "\n",
    "# 2nd conv layer -----------------------\n",
    "W_conv2 = weight_variable([5,5,32,64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d_same(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)  # (26,26) ==> (13,13)\n",
    "\n",
    "\n",
    "\n",
    "# 컨벌루션 레이어 추가!\n",
    "# 3rd conv layer --------------------------\n",
    "W_conv3 = weight_variable([4,4,64,128])\n",
    "b_conv3 = bias_variable([128])\n",
    "\n",
    "h_conv3 = tf.nn.relu(conv2d_valid(h_pool2, W_conv3) + b_conv3)  # (13,13) ==> (10,10)\n",
    "h_pool3 = max_pool_2x2(h_conv3) # (10,10) ==> (5,5)\n",
    "\n",
    "# 4th conv layer -----------------------------\n",
    "W_conv4 = weight_variable([2,2,128,256])\n",
    "b_conv4 = bias_variable([256])\n",
    "\n",
    "h_conv4 = tf.nn.relu(conv2d_valid(h_pool3, W_conv4) + b_conv4)  # (5,5) ==> (4,4)\n",
    "h_pool4 = max_pool_2x2(h_conv4) # (4,4) ==> (2,2)\n",
    "\n",
    "\n",
    "# 4th conv layer -----------------------------\n",
    "W_conv5 = weight_variable([4,4,256,512])\n",
    "b_conv5 = bias_variable([512])\n",
    "\n",
    "h_conv5 = tf.nn.relu(conv2d_same(h_pool4, W_conv5) + b_conv5)\n",
    "h_pool5 = max_pool_2x2(h_conv5) # (2,2) ==> (1,1)\n",
    "\n",
    "\n",
    "# 4th conv layer -----------------------------\n",
    "W_conv6 = weight_variable([4,4,512,1024])\n",
    "b_conv6 = bias_variable([1024])\n",
    "\n",
    "h_conv6 = tf.nn.relu(conv2d_same(h_pool5, W_conv6) + b_conv6)   # (1,1) ==> (1,1)\n",
    "\n",
    "\n",
    "\n",
    "# 1st fully connected layer -----------------------\n",
    "W_fc1 = weight_variable([1*1*1024, 5000])\n",
    "b_fc1 = bias_variable([5000])\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_conv6, [-1, 1*1*1024])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "# 위 연산으로 3000x1의 벡터가 생성된다\n",
    "\n",
    "\n",
    "\n",
    "# Dropout ------------------------\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "\n",
    "\n",
    "# 2nd fully connected layer --------------\n",
    "W_fc2 = weight_variable([5000, 13])\n",
    "b_fc2 = bias_variable([13])\n",
    "y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n",
    "\n",
    "\n",
    "# learning_rate 잘 설정하는게 중요하다.. 0.1로 하니 전혀 변화가 없었다\n",
    "learning_rate = 1e-3\n",
    "\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=y_conv))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "\n",
    "# 정답률을 계산한다  y_conv  vs  y\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 training_accuracy 0.98 cost 0.0225976\n",
      "step 5 training_accuracy 0.98 cost 0.162227\n",
      "step 10 training_accuracy 0.98 cost 0.106238\n",
      "step 15 training_accuracy 1.0 cost 0.000627186\n",
      "[+] Done Save\n"
     ]
    }
   ],
   "source": [
    "#----------------------------------------------\n",
    "batch_size = 50      # 한 루프에 몇개의 (Image, Label) 데이터를 학습하는지 설정\n",
    "display_step = 5   # 루프를 돌면서 화면에 표시할 빈도 설정\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "for i in range(20):\n",
    "    costVal = 0.\n",
    "    batch = next_batch(batch_size)\n",
    "    # 20번 돌릴 때마다 결과를 확인한다\n",
    "    if i % display_step == 0:\n",
    "        train_accuracy = sess.run(accuracy,feed_dict={x:batch[0], y:batch[1], keep_prob:1.0})\n",
    "        costVal = sess.run(cost, feed_dict={x: batch[0], y: batch[1], keep_prob:1.0})\n",
    "    \n",
    "        print('step', i , 'training_accuracy', train_accuracy,'cost', costVal)\n",
    "        \n",
    "        # 실제 학습과정 함수, dropout 50%를 토대로 학습한다\n",
    "    sess.run(optimizer,feed_dict={x:batch[0],y:batch[1], keep_prob:0.5})\n",
    "    if(i == 19):\n",
    "        saver.save(sess, \"d:/edward/hangeul3\")\n",
    "        print(\"[+] Done Save\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy 0.914541\n"
     ]
    }
   ],
   "source": [
    "# 전부 학습이 끝나면 테스트 데이터를 넣어 정확도를 계산한다\n",
    "test_accuracy = sess.run(accuracy,feed_dict={x: test_images, y: test_labels, keep_prob: 1.0})\n",
    "print('test accuracy', test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C://Users//edward//GoogleDrive//private2//machineLearningData//modelSaved//hangeul3\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Unsuccessful TensorSliceReader constructor: Failed to find any matching files for C://Users//edward//GoogleDrive//private2//machineLearningData//modelSaved//hangeul3\n\t [[Node: save_1/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save_1/Const_0, save_1/RestoreV2/tensor_names, save_1/RestoreV2/shape_and_slices)]]\n\nCaused by op 'save_1/RestoreV2', defined at:\n  File \"c:\\programdata\\anaconda3\\envs\\tf\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"c:\\programdata\\anaconda3\\envs\\tf\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"c:\\programdata\\anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"c:\\programdata\\anaconda3\\envs\\tf\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"c:\\programdata\\anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"c:\\programdata\\anaconda3\\envs\\tf\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"c:\\programdata\\anaconda3\\envs\\tf\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"c:\\programdata\\anaconda3\\envs\\tf\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\programdata\\anaconda3\\envs\\tf\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"c:\\programdata\\anaconda3\\envs\\tf\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"c:\\programdata\\anaconda3\\envs\\tf\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"c:\\programdata\\anaconda3\\envs\\tf\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\programdata\\anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"c:\\programdata\\anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"c:\\programdata\\anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"c:\\programdata\\anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"c:\\programdata\\anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"c:\\programdata\\anaconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2683, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"c:\\programdata\\anaconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2787, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"c:\\programdata\\anaconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2847, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-9-192037f7b2d2>\", line 1, in <module>\n    saver = tf.train.Saver()\n  File \"c:\\programdata\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1056, in __init__\n    self.build()\n  File \"c:\\programdata\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1086, in build\n    restore_sequentially=self._restore_sequentially)\n  File \"c:\\programdata\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 691, in build\n    restore_sequentially, reshape)\n  File \"c:\\programdata\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 407, in _AddRestoreOps\n    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)\n  File \"c:\\programdata\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 247, in restore_op\n    [spec.tensor.dtype])[0])\n  File \"c:\\programdata\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\", line 669, in restore_v2\n    dtypes=dtypes, name=name)\n  File \"c:\\programdata\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"c:\\programdata\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"c:\\programdata\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nNotFoundError (see above for traceback): Unsuccessful TensorSliceReader constructor: Failed to find any matching files for C://Users//edward//GoogleDrive//private2//machineLearningData//modelSaved//hangeul3\n\t [[Node: save_1/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save_1/Const_0, save_1/RestoreV2/tensor_names, save_1/RestoreV2/shape_and_slices)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32mc:\\programdata\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1038\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1040\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1021\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1022\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\anaconda3\\envs\\tf\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m                 \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[1;34m()\u001b[0m\n\u001b[0;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 466\u001b[1;33m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[0;32m    467\u001b[0m   \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for C://Users//edward//GoogleDrive//private2//machineLearningData//modelSaved//hangeul3\n\t [[Node: save_1/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save_1/Const_0, save_1/RestoreV2/tensor_names, save_1/RestoreV2/shape_and_slices)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-192037f7b2d2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0msess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0msaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'C://Users//edward//GoogleDrive//private2//machineLearningData//modelSaved//hangeul3'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\programdata\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36mrestore\u001b[1;34m(self, sess, save_path)\u001b[0m\n\u001b[0;32m   1455\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Restoring parameters from %s\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1456\u001b[0m     sess.run(self.saver_def.restore_op_name,\n\u001b[1;32m-> 1457\u001b[1;33m              {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[0;32m   1458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1459\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    776\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 778\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    779\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    980\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 982\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    983\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1030\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1032\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1033\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32mc:\\programdata\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1050\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1051\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1052\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1053\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1054\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for C://Users//edward//GoogleDrive//private2//machineLearningData//modelSaved//hangeul3\n\t [[Node: save_1/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save_1/Const_0, save_1/RestoreV2/tensor_names, save_1/RestoreV2/shape_and_slices)]]\n\nCaused by op 'save_1/RestoreV2', defined at:\n  File \"c:\\programdata\\anaconda3\\envs\\tf\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"c:\\programdata\\anaconda3\\envs\\tf\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"c:\\programdata\\anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"c:\\programdata\\anaconda3\\envs\\tf\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"c:\\programdata\\anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"c:\\programdata\\anaconda3\\envs\\tf\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"c:\\programdata\\anaconda3\\envs\\tf\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"c:\\programdata\\anaconda3\\envs\\tf\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\programdata\\anaconda3\\envs\\tf\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"c:\\programdata\\anaconda3\\envs\\tf\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"c:\\programdata\\anaconda3\\envs\\tf\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"c:\\programdata\\anaconda3\\envs\\tf\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\programdata\\anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"c:\\programdata\\anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"c:\\programdata\\anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"c:\\programdata\\anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"c:\\programdata\\anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"c:\\programdata\\anaconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2683, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"c:\\programdata\\anaconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2787, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"c:\\programdata\\anaconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2847, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-9-192037f7b2d2>\", line 1, in <module>\n    saver = tf.train.Saver()\n  File \"c:\\programdata\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1056, in __init__\n    self.build()\n  File \"c:\\programdata\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1086, in build\n    restore_sequentially=self._restore_sequentially)\n  File \"c:\\programdata\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 691, in build\n    restore_sequentially, reshape)\n  File \"c:\\programdata\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 407, in _AddRestoreOps\n    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)\n  File \"c:\\programdata\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 247, in restore_op\n    [spec.tensor.dtype])[0])\n  File \"c:\\programdata\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\", line 669, in restore_v2\n    dtypes=dtypes, name=name)\n  File \"c:\\programdata\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"c:\\programdata\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"c:\\programdata\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nNotFoundError (see above for traceback): Unsuccessful TensorSliceReader constructor: Failed to find any matching files for C://Users//edward//GoogleDrive//private2//machineLearningData//modelSaved//hangeul3\n\t [[Node: save_1/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save_1/Const_0, save_1/RestoreV2/tensor_names, save_1/RestoreV2/shape_and_slices)]]\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "sess = tf.Session()\n",
    "\n",
    "saver.restore(sess, 'C:/Users/edward/GoogleDrive/private2/machineLearningData/modelSaved/hangeul3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1825\n",
      "Label:  [6]\n",
      "Prediction:  [6]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIRZ4BXI7AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x133c7048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#----------------------------------------------\n",
    "# 임의의 얼굴 하나를 출력한 다음 맞혀보는 코드 \n",
    "test_num_examples , bin2 = test_images.shape\n",
    "r = random.randint(0, test_num_examples -1)\n",
    "print(r)\n",
    "print (\"Label: \", sess.run(tf.argmax(test_labels[r:r+1], 1)))\n",
    "print (\"Prediction: \", sess.run(tf.argmax(y_conv, 1), {x:test_images[r:r+1], keep_prob:1.0}))\n",
    "\n",
    "plt.imshow(test_images[r:r+1].reshape(52, 52), cmap='gray_r', interpolation='nearest')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
